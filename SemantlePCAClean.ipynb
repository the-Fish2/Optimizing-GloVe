{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up x initially\n",
    "x = []\n",
    "with open(\"glove.6B.300d.txt\", 'r') as f:\n",
    "    with open(\"WordFiles/gloveWords.txt\", 'w') as f2:\n",
    "        for i in range(1000):\n",
    "            s = next(f).split(\" \")\n",
    "            f2.write(s[0] + \"\\n\")\n",
    "            s = s[1:]\n",
    "            s[len(s) - 1] = s[len(s) - 1].split('\\n')[0]\n",
    "            x.append(s)\n",
    "# print(x)\n",
    "# x = np.asarray(x)\n",
    "\n",
    "#never run again. now use storeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up x initially\n",
    "\n",
    "keepX = x\n",
    "# print(type(keepX))\n",
    "# print(keepX[1][1])\n",
    "# print([keepX[i+1] for i in range(1)])\n",
    "# print([keepX[1][i] for i in range(len(keepX[1]))])\n",
    "with open(\"WordFiles/storeX.txt\", 'w') as f:\n",
    "    for j in range(1000):\n",
    "        for i in range(len(keepX[j])):\n",
    "            f.write(keepX[j][i] + \" \")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "with open(\"WordFiles/storeX.txt\", 'r') as f:\n",
    "    for i in range(1000):\n",
    "        s = next(f).split(\" \")\n",
    "        x.append(s[:len(s)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepX = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1000):\n",
    "    for i in range(len(keepX[j])):\n",
    "        keepX[j][i] = float(keepX[j][i])\n",
    "        if (len(keepX[j]) != 300):\n",
    "            print(\"uh-oh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "with open(\"WordFiles/gloveWords.txt\", 'r') as f:\n",
    "    for i in range(1000):\n",
    "        s = f.readline()\n",
    "        s = s[:len(s)-1]\n",
    "        z.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3, 42, 37, 153, 12, 20],\n",
       " [1, 2, 5, 34, 110, 150, 143],\n",
       " [4, 275, 54, 667, 190, 94, 414],\n",
       " [6, 111, 76, 108, 0, 229, 147],\n",
       " [7, 170, 37, 48, 14],\n",
       " [8, 175, 434, 53, 805, 225, 52],\n",
       " [9, 784, 26, 47, 12, 18, 71],\n",
       " [10, 79, 2, 110, 19, 61, 106],\n",
       " [11, 65, 167, 97, 811, 57, 300],\n",
       " [13, 177, 171, 183, 185],\n",
       " [15, 134, 51, 40, 168],\n",
       " [16, 154, 210, 391, 345, 859, 374],\n",
       " [17, 150, 5, 110, 143, 52],\n",
       " [21, 134, 51, 30, 15],\n",
       " [22, 111, 2, 79, 355, 6, 587],\n",
       " [23, 24, 89, 274, 652, 45, 1],\n",
       " [25, 137, 263, 781, 66],\n",
       " [27, 28, 932, 16, 53, 188, 154],\n",
       " [29, 170, 37, 12, 42, 48, 7],\n",
       " [31, 33, 744, 51, 411, 39],\n",
       " [32, 158, 155, 109, 39],\n",
       " [35, 51, 155, 134, 39],\n",
       " [36, 70, 34, 119, 54, 88, 413],\n",
       " [38, 18, 52, 33, 442, 103, 26],\n",
       " [41, 81, 462, 472, 588, 769, 70],\n",
       " [43, 54, 189, 287, 94],\n",
       " [44, 261, 162, 39, 47, 53, 33],\n",
       " [46, 900, 871, 86, 130, 773, 456],\n",
       " [49, 106, 284, 61, 76, 127, 378],\n",
       " [50, 196, 58, 215, 2, 126, 245],\n",
       " [55, 87, 133, 174, 228],\n",
       " [56, 73, 440, 181, 338, 151, 34],\n",
       " [59, 77, 204, 73, 102, 109, 306],\n",
       " [60, 135, 66, 339, 120, 189, 222],\n",
       " [62, 76, 229, 265, 82],\n",
       " [63, 84, 34, 64, 149, 130, 413],\n",
       " [67, 71, 18, 808, 787, 103, 26],\n",
       " [68, 125, 109, 201, 144, 77, 306],\n",
       " [69, 423, 155, 338, 109, 68],\n",
       " [72, 486, 262, 686, 800, 540, 571],\n",
       " [74, 82, 76, 59, 60, 363, 265],\n",
       " [75, 66, 127, 131, 137, 60, 339],\n",
       " [78, 466, 568, 148, 347],\n",
       " [80, 93, 230, 160, 642],\n",
       " [83, 36, 260, 189, 70],\n",
       " [85, 661, 79, 701, 770, 332, 151],\n",
       " [90, 854, 763, 272, 443, 367, 613],\n",
       " [91, 34, 48, 36, 151, 413],\n",
       " [92, 347, 112, 78, 358],\n",
       " [95, 99, 233, 230, 112, 710, 860],\n",
       " [96, 109, 56, 858, 48, 77, 306],\n",
       " [98, 838, 621, 436, 550, 798, 903],\n",
       " [100, 34, 317, 113, 151, 413],\n",
       " [101, 39, 103, 155, 64, 33, 53],\n",
       " [104, 112, 99, 471, 140, 95],\n",
       " [105, 49, 249, 566, 76, 106, 284],\n",
       " [107, 414, 647, 94, 396],\n",
       " [114, 149, 20, 14, 34, 37],\n",
       " [115, 328, 237, 111, 351, 633, 619],\n",
       " [116, 433, 159, 34, 263],\n",
       " [117, 125, 151, 81, 188, 68, 158],\n",
       " [118, 150, 55, 42, 5, 52],\n",
       " [121, 640, 198, 0, 513, 734, 672],\n",
       " [122, 249, 147, 766, 229, 517, 265],\n",
       " [123, 513, 252, 411, 31, 471, 112],\n",
       " [124, 42, 82, 215, 2, 12, 20],\n",
       " [128, 337, 258, 459, 731],\n",
       " [129, 503, 235, 734, 243, 393, 381],\n",
       " [132, 327, 942, 694, 729, 727],\n",
       " [136, 903, 786, 105, 233, 838, 798],\n",
       " [138, 66, 420, 137, 120, 60, 339],\n",
       " [139, 193, 637, 574, 482, 685, 529],\n",
       " [141, 335, 536, 205, 78, 239, 466],\n",
       " [142, 568, 898, 941, 148],\n",
       " [145, 776, 535, 879, 479, 292, 449],\n",
       " [146, 701, 85, 471, 243, 661, 79],\n",
       " [152, 653, 164, 609, 505, 888, 543],\n",
       " [156, 843, 37, 62, 2, 20, 215],\n",
       " [157, 38, 564, 276, 598, 18, 52],\n",
       " [161, 500, 850, 762, 751, 914, 462],\n",
       " [163, 111, 420, 137, 242, 6, 587],\n",
       " [165, 935, 590, 577, 367, 742, 613],\n",
       " [166, 748, 601, 447, 298, 742],\n",
       " [169, 881, 405, 81, 70, 769],\n",
       " [172, 293, 962, 493, 687],\n",
       " [173, 636, 82, 100, 34, 363, 265],\n",
       " [176, 232, 314, 409, 422],\n",
       " [178, 330, 340, 400, 666],\n",
       " [179, 102, 100, 222, 53, 197, 346],\n",
       " [180, 234, 622, 456, 880, 109, 871],\n",
       " [182, 43, 287, 781, 106, 54, 189],\n",
       " [184, 171, 177, 183, 185],\n",
       " [186, 290, 282, 479, 648, 697, 334],\n",
       " [187, 373, 326, 63, 53, 781, 242],\n",
       " [191, 100, 317, 588, 143, 34],\n",
       " [192, 392, 41, 285, 162, 81, 462],\n",
       " [194, 340, 178, 148, 142, 400, 330],\n",
       " [195, 292, 62, 186, 290, 535, 76],\n",
       " [199, 288, 168, 350, 49, 127],\n",
       " [200, 293, 255, 239, 687],\n",
       " [202, 924, 305, 801, 451, 846],\n",
       " [203, 733, 102, 70, 346, 197],\n",
       " [206, 404, 324, 421, 657],\n",
       " [207, 106, 378, 61, 127, 49],\n",
       " [208, 60, 339, 182, 79, 135, 66],\n",
       " [209, 659, 935, 165, 577, 631],\n",
       " [211, 818, 452, 468, 755, 544, 895],\n",
       " [212, 376, 413, 34, 12],\n",
       " [213, 915, 629, 808, 630],\n",
       " [214, 973, 82, 756, 151, 363, 265],\n",
       " [216, 497, 276, 283, 330, 616, 941],\n",
       " [217, 632, 524, 409, 867],\n",
       " [218, 891, 248, 388, 833, 498, 242],\n",
       " [219, 439, 588, 690, 81, 269, 873],\n",
       " [220, 598, 594, 48, 892, 239, 321],\n",
       " [221, 499, 164, 543, 806],\n",
       " [223, 109, 158, 201, 77],\n",
       " [224, 882, 444, 594, 481, 506, 638],\n",
       " [226, 389, 878, 602, 295, 715, 895],\n",
       " [227, 877, 320, 651, 402],\n",
       " [231, 994, 323, 395, 783, 828, 251],\n",
       " [236, 48, 359, 87, 55, 170, 91],\n",
       " [238, 596, 906, 51, 12, 667, 862],\n",
       " [240, 277, 185, 183, 184],\n",
       " [241, 79, 2, 111, 6, 61, 106],\n",
       " [244, 109, 68, 423, 77],\n",
       " [246, 79, 82, 73, 48, 61, 106],\n",
       " [247, 582, 263, 190, 492, 76, 388],\n",
       " [250, 109, 68, 910, 201, 77, 306],\n",
       " [253, 81, 102, 326, 662, 769, 70],\n",
       " [254, 439, 219, 877, 143],\n",
       " [256, 767, 431, 666, 338, 336, 400],\n",
       " [257, 802, 286, 6, 241, 448, 700],\n",
       " [259, 322, 193, 556, 139],\n",
       " [264, 830, 743, 347, 202, 78, 92],\n",
       " [266, 301, 787, 67, 461, 300, 808],\n",
       " [267, 472, 222, 588, 269, 242],\n",
       " [268, 424, 634, 78, 123, 851, 316],\n",
       " [270, 522, 2, 172, 849, 1, 34],\n",
       " [271, 964, 915, 69, 808, 213],\n",
       " [273, 970, 896, 816, 458],\n",
       " [278, 42, 424, 622, 234, 12, 20],\n",
       " [279, 870, 649, 893, 923, 272, 443],\n",
       " [280, 761, 677, 562, 275],\n",
       " [281, 789, 273, 58, 816, 168, 376],\n",
       " [289, 112, 99, 104, 443],\n",
       " [291, 525, 644, 252, 354, 471, 112],\n",
       " [294, 126, 469, 550, 182, 245, 689],\n",
       " [296, 84, 130, 36, 151],\n",
       " [297, 695, 803, 348, 516, 603, 387],\n",
       " [299, 661, 432, 58, 96, 332, 151],\n",
       " [302, 399, 19, 15, 168, 52, 143],\n",
       " [303, 70, 88, 81, 346],\n",
       " [304, 396, 617, 344, 478],\n",
       " [307, 976, 797, 242, 887, 222, 326],\n",
       " [308, 872, 642, 169, 181, 783, 772],\n",
       " [309, 551, 465, 754, 49, 781, 222],\n",
       " [310, 875, 469, 768, 717],\n",
       " [311, 225, 564, 215, 454, 19, 175],\n",
       " [312, 857, 251, 211, 969, 643, 452],\n",
       " [313, 520, 749, 705, 0, 806, 732],\n",
       " [315, 406, 463, 349, 545, 370, 677],\n",
       " [318, 710, 233, 959, 463],\n",
       " [319, 254, 369, 974, 523, 439, 219],\n",
       " [325, 352, 178, 340, 815],\n",
       " [329, 381, 165, 577, 321, 286, 935],\n",
       " [331, 797, 385, 156, 215, 307, 531],\n",
       " [333, 181, 530, 317, 936, 151, 73],\n",
       " [341, 397, 82, 33, 363, 993, 350],\n",
       " [342, 387, 796, 348, 750],\n",
       " [343, 573, 591, 599, 548],\n",
       " [353, 219, 143, 858, 181, 439, 588],\n",
       " [356, 713, 597, 650, 703, 813, 775],\n",
       " [357, 426, 306, 333, 158, 77, 109],\n",
       " [360, 757, 631, 749, 659, 888, 726],\n",
       " [361, 623, 574, 132, 831, 139, 193],\n",
       " [362, 276, 369, 719, 823, 616, 941],\n",
       " [364, 277, 240, 766, 185],\n",
       " [365, 882, 117, 70, 426, 506, 224],\n",
       " [366, 879, 550, 294, 320, 698, 145],\n",
       " [368, 619, 237, 482, 828],\n",
       " [371, 631, 716, 394, 466, 888, 360],\n",
       " [372, 73, 151, 56, 440],\n",
       " [375, 396, 344, 478, 441],\n",
       " [377, 386, 633, 237, 328],\n",
       " [379, 629, 630, 431, 617],\n",
       " [380, 716, 251, 969, 552, 427],\n",
       " [382, 627, 446, 393, 534],\n",
       " [383, 717, 60, 135, 120, 768],\n",
       " [384, 771, 877, 299, 62, 350, 76],\n",
       " [390, 189, 408, 86, 83, 911, 94],\n",
       " [398, 367, 763, 968, 443, 613, 538],\n",
       " [401, 414, 995, 189, 738, 94, 54],\n",
       " [403, 813, 597, 775, 974],\n",
       " [407, 324, 579, 404, 800],\n",
       " [410, 594, 321, 126, 245],\n",
       " [412, 467, 132, 545, 874, 327, 942],\n",
       " [415, 296, 779, 887, 455, 84, 130],\n",
       " [416, 138, 592, 635, 405, 66, 420],\n",
       " [417, 473, 830, 786, 503, 264, 202],\n",
       " [418, 676, 421, 657, 904],\n",
       " [419, 933, 761, 779, 687, 275, 901],\n",
       " [425, 91, 20, 42, 2, 34, 48],\n",
       " [428, 859, 986, 493, 172, 154, 293],\n",
       " [429, 239, 200, 345, 148],\n",
       " [430, 620, 937, 565, 851, 385, 954],\n",
       " [435, 547, 737, 953, 758, 847, 54],\n",
       " [437, 150, 669, 449, 34, 52, 5],\n",
       " [438, 502, 174, 739, 228],\n",
       " [445, 712, 113, 212, 504, 34, 100],\n",
       " [450, 617, 470, 478, 487],\n",
       " [453, 525, 140, 513, 112, 291, 831],\n",
       " [457, 171, 177, 183, 184],\n",
       " [460, 4, 390, 949, 36, 275, 54],\n",
       " [464, 82, 519, 271, 964, 363, 265],\n",
       " [474, 792, 656, 603, 132, 803, 563],\n",
       " [475, 178, 194, 141, 536, 330, 340],\n",
       " [476, 741, 345, 154, 119, 303, 374],\n",
       " [477, 93, 573, 558, 686, 160, 230],\n",
       " [480, 748, 443, 693, 264, 742, 601],\n",
       " [483, 54, 94, 451, 43],\n",
       " [484, 256, 436, 798, 666, 767, 431],\n",
       " [485, 262, 756, 69, 501, 72, 682],\n",
       " [488, 144, 680, 125, 68],\n",
       " [489, 94, 54, 712, 754],\n",
       " [490, 736, 545, 574, 634, 139, 193],\n",
       " [491, 211, 586, 385, 447, 818, 452],\n",
       " [494, 917, 158, 793, 215, 201, 68],\n",
       " [495, 615, 995, 747, 189, 401, 738],\n",
       " [496, 454, 646, 25, 40, 455, 215],\n",
       " [507, 26, 261, 44, 38, 18, 71],\n",
       " [508, 436, 714, 256, 397, 767, 431],\n",
       " [509, 514, 525, 387, 931, 291, 831],\n",
       " [510, 617, 478, 441, 450],\n",
       " [511, 408, 102, 37, 189, 911, 390],\n",
       " [512, 829, 447, 501, 589, 675, 916],\n",
       " [515, 681, 705, 849, 458],\n",
       " [518, 40, 33, 51, 332, 39],\n",
       " [521, 298, 639, 989, 685],\n",
       " [526, 211, 468, 686, 72, 818, 452],\n",
       " [527, 466, 251, 511, 189, 78, 272],\n",
       " [528, 286, 187, 370, 809, 448, 700],\n",
       " [532, 641, 692, 230, 236, 800, 558],\n",
       " [533, 943, 0, 47, 839, 3, 42],\n",
       " [537, 500, 869, 161, 354],\n",
       " [539, 735, 836, 982, 523],\n",
       " [541, 151, 822, 253, 19, 34, 413],\n",
       " [542, 19, 481, 791, 334, 52, 143],\n",
       " [546, 349, 677, 37, 751, 370],\n",
       " [549, 64, 47, 91, 34, 155, 68],\n",
       " [553, 34, 413, 36, 151],\n",
       " [554, 483, 833, 137, 168, 54, 94],\n",
       " [555, 130, 414, 94, 647, 84, 36],\n",
       " [557, 454, 52, 37, 10, 455, 215],\n",
       " [559, 394, 457, 54, 847, 171, 177],\n",
       " [560, 864, 571, 755, 686],\n",
       " [561, 707, 245, 126, 66, 182],\n",
       " [567, 120, 102, 588, 70, 222, 20],\n",
       " [569, 61, 587, 669, 256, 127, 106],\n",
       " [570, 889, 533, 173, 647, 871, 179],\n",
       " [572, 770, 877, 227, 320, 958, 85],\n",
       " [575, 100, 911, 667, 70, 34, 317],\n",
       " [576, 355, 237, 447, 675, 587, 111],\n",
       " [578, 101, 303, 595, 408, 39, 103],\n",
       " [580, 971, 175, 476, 303, 225, 52],\n",
       " [581, 555, 54, 43, 94, 130, 414],\n",
       " [583, 954, 937, 138, 694, 482],\n",
       " [584, 703, 650, 655, 585],\n",
       " [593, 544, 452, 72, 626],\n",
       " [600, 101, 17, 500, 39],\n",
       " [604, 712, 687, 367, 896, 445, 113],\n",
       " [605, 317, 588, 100, 169],\n",
       " [606, 249, 599, 517, 766],\n",
       " [607, 237, 619, 153, 0],\n",
       " [608, 130, 190, 492, 483, 84, 36],\n",
       " [610, 58, 145, 282, 186, 126, 245],\n",
       " [611, 54, 343, 339, 94],\n",
       " [612, 145, 535, 865, 479, 776],\n",
       " [614, 628, 930, 796, 856],\n",
       " [618, 128, 526, 459, 316, 337, 258],\n",
       " [624, 482, 368, 529, 828],\n",
       " [625, 705, 237, 139, 586, 355],\n",
       " [645, 588, 873, 936, 654, 269],\n",
       " [658, 283, 246, 19, 172, 466, 358],\n",
       " [660, 754, 43, 189, 54],\n",
       " [663, 616, 446, 854, 276],\n",
       " [664, 914, 161, 500, 439, 751, 267],\n",
       " [665, 778, 812, 885, 918],\n",
       " [668, 613, 577, 538, 367],\n",
       " [670, 103, 18, 26, 300, 101],\n",
       " [671, 747, 615, 113, 445, 495, 34],\n",
       " [673, 609, 468, 653, 864, 626, 211],\n",
       " [674, 680, 223, 488, 68, 144],\n",
       " [678, 975, 230, 160, 857],\n",
       " [679, 355, 328, 800, 558, 587, 111],\n",
       " [683, 42, 871, 880, 86, 12, 20],\n",
       " [684, 870, 785, 279, 893],\n",
       " [688, 127, 263, 137, 66, 61, 378],\n",
       " [691, 819, 630, 629, 103],\n",
       " [696, 657, 759, 676, 904],\n",
       " [699, 322, 153, 156, 0, 259, 193],\n",
       " [702, 808, 629, 71, 630],\n",
       " [704, 248, 215, 79, 483, 218, 137],\n",
       " [706, 553, 34, 36, 12],\n",
       " [708, 709, 585, 782, 812, 650],\n",
       " [711, 563, 348, 297, 982, 603, 695],\n",
       " [718, 385, 529, 400, 482, 531, 5],\n",
       " [720, 378, 168, 61, 106],\n",
       " [721, 395, 794, 251, 701],\n",
       " [722, 292, 776, 145, 879, 535, 195],\n",
       " [723, 731, 128, 783, 486],\n",
       " [724, 302, 19, 762, 207, 399],\n",
       " [725, 770, 912, 528, 879, 958, 85],\n",
       " [728, 58, 550, 126, 182],\n",
       " [730, 750, 471, 985, 194, 252, 340],\n",
       " [740, 62, 195, 105, 807, 76, 229],\n",
       " [745, 950, 628, 92, 856, 930, 614],\n",
       " [746, 179, 120, 222, 190, 102, 100],\n",
       " [752, 547, 76, 294, 156, 435, 737],\n",
       " [753, 648, 254, 479, 816],\n",
       " [760, 850, 403, 299, 161],\n",
       " [764, 227, 85, 877, 230],\n",
       " [765, 272, 443, 763, 466],\n",
       " [774, 603, 695, 112, 104, 803, 563],\n",
       " [777, 820, 293, 172, 246, 687, 255],\n",
       " [780, 811, 582, 791, 846, 577, 98],\n",
       " [788, 825, 371, 631, 178, 957, 340],\n",
       " [790, 632, 652, 524, 422],\n",
       " [795, 947, 579, 952, 904],\n",
       " [799, 122, 785, 923, 384, 249, 147],\n",
       " [804, 269, 645, 102, 965, 588, 346],\n",
       " [810, 969, 118, 251, 252, 150, 55],\n",
       " [814, 96, 109, 858, 399],\n",
       " [817, 325, 437, 2, 135, 352, 178],\n",
       " [821, 664, 500, 276, 598, 914, 161],\n",
       " [824, 733, 53, 326, 938, 203, 269],\n",
       " [826, 504, 578, 339, 113, 34, 212],\n",
       " [827, 140, 69, 155, 99],\n",
       " [832, 394, 693, 772, 160, 559, 54],\n",
       " [834, 96, 19, 30, 113, 109, 56],\n",
       " [835, 81, 285, 690, 588, 769, 70],\n",
       " [837, 595, 222, 914, 578, 977, 841],\n",
       " [840, 876, 801, 898, 305],\n",
       " [842, 275, 761, 677, 565, 4, 963],\n",
       " [844, 865, 783, 395, 258, 872, 755],\n",
       " [845, 263, 938, 61, 326, 76, 388],\n",
       " [848, 977, 119, 968, 4, 595, 841],\n",
       " [852, 890, 442, 61, 127, 332],\n",
       " [853, 413, 113, 102, 12, 376, 34],\n",
       " [855, 70, 88, 81, 346],\n",
       " [861, 880, 793, 125, 68],\n",
       " [863, 985, 447, 313, 927, 730, 352],\n",
       " [866, 402, 712, 548, 651, 445, 113],\n",
       " [868, 202, 924, 264, 305],\n",
       " [883, 254, 439, 143, 219],\n",
       " [884, 535, 172, 290, 816, 292, 449],\n",
       " [886, 303, 81, 769, 242, 70, 88],\n",
       " [894, 261, 26, 392, 192, 44],\n",
       " [897, 871, 0, 989, 91, 773, 900],\n",
       " [899, 300, 787, 48, 69],\n",
       " [902, 538, 748, 668, 577, 367, 613],\n",
       " [905, 164, 543, 215, 880, 888],\n",
       " [907, 159, 433, 260, 934],\n",
       " [908, 659, 501, 214, 734, 631, 209],\n",
       " [909, 337, 565, 526, 459, 128],\n",
       " [913, 472, 41, 267, 588],\n",
       " [919, 987, 526, 128, 909, 211, 468],\n",
       " [920, 984, 734, 243, 261, 955, 675],\n",
       " [921, 873, 645, 588, 269],\n",
       " [922, 355, 146, 587, 325],\n",
       " [925, 951, 849, 974, 732],\n",
       " [926, 503, 577, 959, 734, 129, 68],\n",
       " [928, 284, 263, 49, 58],\n",
       " [929, 215, 47, 680, 0, 37, 79],\n",
       " [939, 867, 655, 703, 584],\n",
       " [940, 62, 229, 686, 122, 76],\n",
       " [944, 948, 149, 660, 578, 114, 34],\n",
       " [945, 400, 644, 340, 860, 666],\n",
       " [946, 885, 996, 918, 778],\n",
       " [956, 468, 686, 211, 287, 626, 609],\n",
       " [960, 320, 651, 550, 227],\n",
       " [961, 287, 755, 647, 211, 43],\n",
       " [966, 82, 265, 517, 249, 363],\n",
       " [967, 831, 327, 685, 252, 132, 942],\n",
       " [972, 305, 791, 906, 840, 846, 801],\n",
       " [978, 219, 654, 873, 113, 439, 588],\n",
       " [979, 175, 834, 19, 15, 225, 52],\n",
       " [980, 918, 996, 885, 946],\n",
       " [981, 179, 75, 483, 890, 102, 100],\n",
       " [983, 531, 105, 754, 201, 385, 49],\n",
       " [988, 552, 858, 686, 956, 251, 427],\n",
       " [990, 137, 483, 707, 781, 66, 420],\n",
       " [991, 879, 291, 776, 85, 698, 145],\n",
       " [992, 113, 978, 858, 219, 34, 100],\n",
       " [997, 801, 898, 840, 265, 305, 202],\n",
       " [998, 588, 269, 267, 472],\n",
       " [999, 181, 408, 881, 169, 151, 73]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ideal clusters - gloveWordsClusters.txt - don't run again\n",
    "# bash - clusters - NO PCA - stored in clusters.txt\n",
    "\n",
    "#RUN Bash alg\n",
    "#bash list of clusters\n",
    "def cluster_gen(data):\n",
    "    #swap to snake_case\n",
    "    touched_points = []\n",
    "    clusters = []\n",
    "\n",
    "    for i in range (1000):\n",
    "        if i in touched_points:\n",
    "            continue\n",
    "\n",
    "        curr_cluster = make_cluster(i, data)\n",
    "        clusters.append(curr_cluster)\n",
    "        # print(\"check2\")\n",
    "        #print(curr_cluster)\n",
    "        with open(\"WordFiles/clusters2.txt\", \"a\") as f:\n",
    "            for i in range(len(curr_cluster)):\n",
    "                f.write(z[curr_cluster[i]] + \" \")\n",
    "            f.write(\"\\n\")\n",
    "            for i in range(len(curr_cluster)):\n",
    "                f.write(str(curr_cluster[i]) + \" \")\n",
    "            f.write(\"\\n\")\n",
    "            f.close()\n",
    "            #print(z[curr_cluster[i]], end = \" \")\n",
    "        #print()          \n",
    "\n",
    "        touched_points.extend(curr_cluster)\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def find_most_similar(word, total_words, curr_cluster):\n",
    "\n",
    "    m = 0\n",
    "    while m in curr_cluster:\n",
    "        m = m + 1\n",
    "        \n",
    "    min_val = cosine(u = total_words[word], v = total_words[m])\n",
    "    index = m\n",
    "\n",
    "    for i in range(m+1, 1000):\n",
    "        skip = False\n",
    "\n",
    "        if i in curr_cluster:\n",
    "            skip = True\n",
    "\n",
    "        curr_val = cosine(u = total_words[word], v = total_words[i])\n",
    "\n",
    "        if skip:\n",
    "            curr_val = min_val\n",
    "        \n",
    "        if curr_val < min_val:\n",
    "            min_val = curr_val\n",
    "            index = i\n",
    "\n",
    "    if min_val > 0.7:\n",
    "        return word\n",
    "\n",
    "    return index\n",
    "\n",
    "def make_cluster(word, data):\n",
    "    curr_cluster=[]\n",
    "    visited = []\n",
    "    queue = []\n",
    "    queue.append(word)\n",
    "\n",
    "    while len(curr_cluster) < 7 and queue:\n",
    "        curr_word = queue.pop(0)\n",
    "\n",
    "        if curr_word in curr_cluster:\n",
    "            break\n",
    "\n",
    "        curr_cluster.append(curr_word)\n",
    "        visited.append(curr_word)\n",
    "        \n",
    "        #alg:\n",
    "        for i in range(4):\n",
    "\n",
    "            closest_word = find_most_similar(curr_word, data, visited)\n",
    "\n",
    "            if not (closest_word in curr_cluster):\n",
    "                queue.append(closest_word)\n",
    "            \n",
    "            if closest_word == word:\n",
    "                break\n",
    "            \n",
    "            visited.append(closest_word)\n",
    "\n",
    "        #alg2:\n",
    "        visited = []\n",
    "\n",
    "    # if len(curr_cluster) == 1:\n",
    "    #     return []\n",
    "    \n",
    "    return curr_cluster\n",
    "\n",
    "cluster_gen(keepX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcaanal(newDim, arr2):\n",
    "    pca = PCA(n_components = newDim)\n",
    "    pca.fit(arr2)\n",
    "    arr2 = pca.transform(arr2)\n",
    "    return arr2\n",
    "\n",
    "def tsneanal(newDim, arr3):\n",
    "    tsne = TSNE(n_components = newDim, learning_rate = 'auto', init='random', perplexity=newDim).fit_transform(arr3)\n",
    "    return tsne\n",
    "\n",
    "#issue with current places having > 2 dimensions\n",
    "#it doesn't like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_birch(x):\n",
    "    from sklearn.cluster import Birch\n",
    "\n",
    "    brc = Birch(threshold=0.7, n_clusters=142)\n",
    "    #clusters themselves good, need to also analyze LOCATION of clustesr\n",
    "    #for now, 1000/7=142 clusters\n",
    "    x2 = brc.fit_predict(x)\n",
    "\n",
    "    clusters = [[] for x in range(142)]\n",
    "    for i in range(1, 1000):\n",
    "        clusters[x2[i]].append(z[i])\n",
    "\n",
    "    with open(\"WordFiles/gloveWordsBirchClusters.txt\", 'w') as f:\n",
    "        for i in clusters:\n",
    "            for j in i:\n",
    "                f.write(j)\n",
    "                f.write(\" \")\n",
    "            f.write('\\n')\n",
    "    #return clusters\n",
    "\n",
    "run_birch(keepX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x3 \u001b[39m=\u001b[39m tsneanal(\u001b[39m150\u001b[39m, x)\n",
      "Cell \u001b[1;32mIn [98], line 8\u001b[0m, in \u001b[0;36mtsneanal\u001b[1;34m(newDim, arr3)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtsneanal\u001b[39m(newDim, arr3):\n\u001b[1;32m----> 8\u001b[0m     tsne \u001b[39m=\u001b[39m TSNE(n_components \u001b[39m=\u001b[39;49m newDim, learning_rate \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m, init\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m'\u001b[39;49m, perplexity\u001b[39m=\u001b[39;49mnewDim)\u001b[39m.\u001b[39;49mfit_transform(arr3)\n\u001b[0;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m tsne\n",
      "File \u001b[1;32mc:\\Users\\nishk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:1122\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1103\u001b[0m     \u001b[39m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m \n\u001b[0;32m   1105\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[39m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1122\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params_vs_input(X)\n\u001b[0;32m   1123\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit(X)\n\u001b[0;32m   1124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n",
      "File \u001b[1;32mc:\\Users\\nishk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:792\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params_vs_input\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m--> 792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperplexity \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m    793\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mperplexity must be less than n_samples\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x3 = tsneanal(150, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25539, -0.25723, 0.13169, -0.042688, 0.21817, -0.022702, -0.17854, 0.10756, 0.058936, -1.3854, 0.58509, 0.036501, -0.19846, 0.19613, 0.40929, 0.15702, -0.15305, 0.050447, 0.30045, -0.11295, -0.017043, 0.18593, 0.19982, 0.20053, -0.63141, -0.12622, 0.2951, -0.26282, -0.15831, 0.0012383, 0.011784, 0.58758, -0.15914, 0.27731, -0.82343, -0.21134, 0.013414, 0.19637, -0.4147, 0.0010276, 0.13422, -0.14205, 0.051545, 0.34993, -0.29868, -0.3209, 0.19566, 0.47886, 0.10744, 0.010004, 0.18503, 0.080694, 0.20739, -0.097365, -0.039448, 0.020151, -0.17378, 0.25679, 0.24198, -0.351, 0.18759, 0.0063857, 0.18395, -0.13929, 0.0081855, -0.63109, 0.29832, 0.31731, 0.13022, -0.32284, -0.050343, -0.114, 0.12097, 0.14687, -0.33244, -0.055789, -0.05849, 0.27551, -0.043855, 0.039664, 0.15162, -0.086627, 0.067729, 0.23146, 0.015351, -0.15142, -0.031975, 0.45181, -0.068806, -0.077058, 0.055193, 0.054596, -0.24708, 0.031113, -0.12826, 0.12782, -0.46708, -0.026264, 0.010387, -0.33174, 0.17277, -0.26894, 0.20467, -0.16181, -0.041519, -0.014878, 0.10279, 0.18868, -0.23396, -0.018436, -0.14747, -0.32685, -0.022055, -0.054, 0.16264, 0.27095, -0.22792, -0.0077006, 0.11206, -0.039787, -0.11906, 0.021773, 0.05528, -0.13318, -0.056867, 0.008304, -0.027021, 0.23447, 0.086864, 0.12009, -0.30726, 0.0024735, 0.29041, -0.044887, 0.12297, 0.13077, 0.090807, -0.39141, 0.080546, 0.18724, -0.097481, 0.10397, 0.11492, 0.17775, -0.18167, 0.24652, 0.20136, -0.23395, -0.35018, -0.14061, 0.17091, -0.095465, -0.10962, -0.09836, 0.15344, 0.08868, -0.22048, -0.13803, -0.11288, -0.08534, 0.072735, -0.12732, -0.1964, -0.10586, 0.0020616, 0.13496, 0.058912, -0.043979, -0.091375, 0.24408, 0.16872, 0.24297, -0.43983, 0.47089, -0.018595, 0.16146, 0.19828, -0.17237, -0.0026998, 0.52097, -0.080197, 0.43324, -0.066261, 0.04324, 0.084954, -0.14836, -0.41936, 0.15988, -0.18411, 0.1321, 0.27476, 0.27279, -0.13465, -0.091238, -0.32523, 0.27936, 0.023296, -0.33472, 0.016878, -0.055544, 0.92915, -0.33914, -0.14791, 0.017301, 0.18272, 0.35108, -0.11438, 0.13228, -0.021064, -0.27453, -0.10081, -0.046296, 0.21689, -0.056319, 0.14651, -0.023536, 0.068026, -0.045453, -0.23851, -0.33868, 0.31396, -0.031914, -0.019217, 0.0018715, -0.13328, 0.070148, -0.039761, 0.070801, 0.0018422, -0.12646, 0.028675, -0.095728, 0.26673, -0.35536, 0.15286, 0.064565, 0.12647, 0.23397, -0.046058, 0.13519, -0.14549, 0.23031, 0.42066, 0.16267, -0.16541, -0.0020155, 0.080653, -0.30025, -0.076014, 0.070612, 0.3157, 0.05352, -0.10721, -0.1366, 0.32214, 0.2004, 0.11609, -0.22501, 0.12155, -0.10851, -0.063187, -0.24553, -0.059751, 0.068787, -0.11627, -0.0083402, 0.0052044, -0.20159, -0.023663, 0.17562, -0.31475, -0.11162, -0.12492, 0.10949, -0.26913, 0.34893, -1.6997, -0.2447, 0.30292, 0.05672, -0.31737, 0.083612, 0.095949, -0.1759, 0.10235, 0.36808, -0.3438, 0.20607, 0.19135, 0.10992, 0.075968, -0.014359, -0.073794, 0.22176, 0.14652, 0.56686, 0.053307, -0.2329, -0.12226, 0.35499]\n"
     ]
    }
   ],
   "source": [
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check(dim):\n",
    "    x2 = pcaanal(dim, x)\n",
    "    \n",
    "    return True\n",
    "check(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 50\n",
    "\n",
    "def binary_search(n):\n",
    "    low = 1\n",
    "    high = n\n",
    "    mid = 0\n",
    "\n",
    "    while low <= high:\n",
    "        mid = (high+low)//2\n",
    "        if check(mid):\n",
    "            #if it works, want a lower dimension,so\n",
    "            high = mid - 1\n",
    "        else:\n",
    "            low = mid + 1\n",
    "    \n",
    "    return mid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 19.52262   32.46554 ]\n",
      " [ 19.390217  12.237307]\n",
      " [ 12.079992  13.87786 ]\n",
      " ...\n",
      " [-55.804005 -15.671411]\n",
      " [-13.270217 -20.621748]\n",
      " [-47.1446   -41.76552 ]]\n"
     ]
    }
   ],
   "source": [
    "x4 = np.asarray(x)\n",
    "x3 = tsneanal(2, x4)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_birch(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_birch(x3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b035a97ad67dff3ddcf42b4508c859b33be75c134f59f08fe6dd0d28f1650ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
