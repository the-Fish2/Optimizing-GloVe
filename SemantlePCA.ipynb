{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Exists\n",
      "KeyedVectors<vector_size=300, 3000000 keys>\n"
     ]
    }
   ],
   "source": [
    "# RUN general imports\n",
    "\n",
    "import os\n",
    "\n",
    "if not {\"word2vec.model\", \"words.txt\"}.issubset(set(os.listdir())):\n",
    "\n",
    "    print(\"Beginning download\")\n",
    "\n",
    "    import gensim.downloader\n",
    "\n",
    "    print(\"imported\")\n",
    "\n",
    "    wv = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "\n",
    "    print(\"loaded\")\n",
    "\n",
    "    wv.save(\"./word2vec.model\")\n",
    "\n",
    "    print(\"saved\")\n",
    "    \n",
    "    f = open(\"words.txt\", \"x\")\n",
    "    for index, word in enumerate(wv.index_to_key):\n",
    "        if index == 1000:\n",
    "            break\n",
    "        f.write(word)\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "print(\"File Exists\")\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load(\"word2vec.model\", mmap=\"r\")\n",
    "print(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m x \u001b[39m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     x\u001b[39m.\u001b[39mappend(wv[i])\n\u001b[0;32m      8\u001b[0m     \u001b[39m# if (i == 100000):\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39m#     print(\"hi\")\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[39m# if (i == 1000000):\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[39m#     print(\"hi\")\u001b[39;00m\n\u001b[0;32m     12\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wv' is not defined"
     ]
    }
   ],
   "source": [
    "#RUN generates x\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = []\n",
    "for i in range(1000):\n",
    "    x.append(wv[i])\n",
    "    # if (i == 100000):\n",
    "    #     print(\"hi\")\n",
    "    # if (i == 1000000):\n",
    "    #     print(\"hi\")\n",
    "x = np.asarray(x)\n",
    "\n",
    "# x = np.array([])\n",
    "# for i in range(300):\n",
    "#     x = np.append(x, wv[i])\n",
    "#     print(x[i][0], end = \" \")\n",
    "# print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN imports\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#RUN generates array z (words)\n",
    "z = []\n",
    "with open(\"words.txt\", 'r') as f:\n",
    "    for i in range(1000):\n",
    "        s = f.readline()\n",
    "        s = s[:len(s)-1]\n",
    "        z.append(s)\n",
    "\n",
    "print(len(z))\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.keyedvectors.KeyedVectors'>\n",
      "KeyedVectors<vector_size=300, 3000000 keys>\n",
      "KeyedVectors<vector_size=300, 1000 keys>\n"
     ]
    }
   ],
   "source": [
    "#convert keyed vectors to smaller length\n",
    "print(type(wv))\n",
    "print(wv)\n",
    "iterator_for_words = (word for word in z)\n",
    "wv = wv.vectors_for_all(iterator_for_words)\n",
    "print(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN Bash alg\n",
    "#bash list of clusters\n",
    "\n",
    "def cluster_gen(data):\n",
    "    #swap to snake_case\n",
    "    touched_points = []\n",
    "    clusters = []\n",
    "\n",
    "    for i in range (1000):\n",
    "        if i in touched_points:\n",
    "            continue\n",
    "\n",
    "        curr_cluster = make_cluster(i, data)\n",
    "        clusters.append(curr_cluster)\n",
    "        # print(\"check2\")\n",
    "        # print(curr_cluster)\n",
    "        touched_points.extend(curr_cluster)\n",
    "        # print(touched_points)\n",
    "\n",
    "    # call other function to recursively add elements \n",
    "    # curr cluster = list\n",
    "    # append to total list of clusters\n",
    "\n",
    "    return clusters\n",
    "\n",
    "#maybe change algorithm to be like. find clusters of 'two' for closest words\n",
    "#then combine them to make clusters of 4\n",
    "#then 8\n",
    "#so forth\n",
    "#elements can be in multiple clusters\n",
    "#this is agglomerative tho\n",
    "def find_most_similar(word, total_words, curr_cluster):\n",
    "\n",
    "    from scipy.spatial.distance import cosine\n",
    "\n",
    "    m = 0\n",
    "    while m in curr_cluster:\n",
    "        m = m + 1\n",
    "\n",
    "    min_val = cosine(u = total_words[word], v = total_words[m])\n",
    "    index = m\n",
    "\n",
    "    for i in range(m+1, 1000):\n",
    "        skip = False\n",
    "\n",
    "        if i in curr_cluster:\n",
    "            skip = True\n",
    "\n",
    "        # if word[0] == total_words[i][0]:\n",
    "        #     for j in range(2, 300):\n",
    "        #         if (word[j] == total_words[i][j]):\n",
    "        #             skip = True\n",
    "        \n",
    "        curr_val = cosine(u = total_words[word], v = total_words[i])\n",
    "        #print(i, end = \" \")\n",
    "        #print(curr_val)\n",
    "\n",
    "        if skip:\n",
    "            curr_val = min_val\n",
    "        \n",
    "        if curr_val < min_val:\n",
    "            min_val = curr_val\n",
    "            index = i\n",
    "\n",
    "    #print(str(min_val) + \" \" + str(word) + \" \" + str(index))\n",
    "    # def issue - same computation 5 times??\n",
    "\n",
    "    if min_val > 0.7:\n",
    "        return word\n",
    "\n",
    "    return index\n",
    "\n",
    "# ans = find_most_similar(217, x, [217])\n",
    "# print(z[ans])\n",
    "\n",
    "#z = wv\n",
    "def make_cluster(word, data):\n",
    "\n",
    "    # print()\n",
    "\n",
    "    curr_cluster=[]\n",
    "    visited = []\n",
    "    queue = []\n",
    "    queue.append(word)\n",
    "\n",
    "    while len(curr_cluster) < 8 and queue:\n",
    "        curr_word = queue.pop(0)\n",
    "\n",
    "        # print(z[curr_word], end = \" \")\n",
    "\n",
    "        if curr_word in curr_cluster:\n",
    "            break\n",
    "\n",
    "        curr_cluster.append(curr_word)\n",
    "        visited.append(curr_word)\n",
    "        \n",
    "        #alg:\n",
    "        for i in range(5):\n",
    "\n",
    "            closest_word = find_most_similar(curr_word, data, visited)\n",
    "\n",
    "            if not (closest_word in curr_cluster):\n",
    "                queue.append(closest_word)\n",
    "            \n",
    "            if closest_word == word:\n",
    "                break\n",
    "            \n",
    "            visited.append(closest_word)\n",
    "\n",
    "        #alg2:\n",
    "        visited = []\n",
    "\n",
    "    # if len(curr_cluster) == 1:\n",
    "    #     return []\n",
    "    \n",
    "    return curr_cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN Birch Alg + Clusters\n",
    "def run_birch(x):\n",
    "    from sklearn.cluster import Birch\n",
    "\n",
    "    brc = Birch(n_clusters = 323)\n",
    "    x2 = brc.fit_predict(x)\n",
    "\n",
    "    print(x2)\n",
    "\n",
    "    clusters = [[] for x in range(323)]\n",
    "    for i in range(1, 1000):\n",
    "        clusters[x2[i]].append(z[i])\n",
    "\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN storing clusters\n",
    "clusters300 = [['about', 'over', 'into', 'through', 'under', 'between', 'around', 'past'], ['as', 'most', 'well', 'such', 'very', 'long', 'too'], ['found', 'report', 'show'], ['#.#', '#.##', '##.#', 'per'], ['will', 'would', 'can', 'could', 'should', 'may', 'expected'], ['team', 'against', 'group', 'former', 'case'], ['in', 'for', 'on', 'with', 'the', 'from', 'by', 'an', 'who', 'its', 'which', 'also', 'new', 'while', 'including', 'part', 'own', 'called'], ['more', 'than', 'much', 'lot', 'little'], ['said', 'says', 'told', 'added', 'according'], ['is', 'was', 'be', 'are', 'were', 'being'], ['game', 'play', 'games', 'players'], ['get', 'work', 'go', 'got', 'run', 'come', 'put', 'came', 'went'], ['people', 'school', 'children'], ['right', 'left', 'hit'], ['state', 'government', 'public', 'city', 'area', 'local'], ['year', 'season', 'week', 'month'], ['old', 'man'], ['you', 'your', 'You'], ['have', 'has', 'had', 'been', \"'ve\", 'never'], ['officials', 'members'], ['$', 'money'], ['program', 'system'], ['good', 'best', 'better', 'great', 'big'], ['he', 'his', 'her', 'she', 'him'], ['I', 'my', 'us', 'me'], ['years', 'months', 'days', 'ago'], ['based', '&'], ['their', 'they', 'we', 'our', 'them'], ['U.S.', 'world', 'country', 'American'], ['at', 'time', 'day', 'end', 'today', 'set', 'place', 'start'], ['The', 'It', 'A', 'This', 'That'], ['am', 'pm'], ['points', 'point'], ['use', 'used'], [\"'re\", \"'m\"], ['quarter', 'half'], ['#-#', '##-##'], ['or', 'no', 'any', 'without'], ['But', 'If', 'And', 'As'], ['all', 'two', 'other', 'some', 'three', 'many', 'those', 'four', 'five', 'these', 'both', 'six', 'number', 'few'], ['In', 'For'], ['information'], ['think', 'see', 'say', 'know', 'really'], ['up', 'out', 'back', 'off', 'down'], ['percent', '%'], ['this', 'last', 'next', 'another', 'same', 'each', 'every'], ['million', 'billion'], ['By'], ['take', 'took'], ['company', 'business', 'market', 'companies'], ['Friday', 'Tuesday', 'Monday', 'night', 'Thursday', 'Wednesday', 'Saturday', 'Sunday'], ['not', 'do', 'did', 'does', 'want', 'need'], ['that', 'it', 'but', 'one', 'when', 'there', 'just', 'what', 'so', 'like', 'if', 'only', 'because', 'now', 'where', 'going', 'way', 'how', 'then', 'still', 'even', 'here'], ['made', 'make'], ['services', 'service'], ['##', '###', '1', '2', '3', '5'], ['There'], ['home', 'family', 'life'], ['high', 'top'], ['#,###', '##,###', '###,###'], ['State'], ['####', 'after', 'before', 'during', 'since', 'early', 'until'], ['win', 'lead'], ['We', 'They'], ['first', 'second', 'third', '##th'], ['help', 'support'], ['sales'], ['AP'], ['He', 'She'], ['police']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe just like\n",
    "#add in 'new element' and if adds into another cluster with minimum distance < x\n",
    "#then allow it?\n",
    "#this may not be necessary; all that has to be done to check is like to confirm that faraway points still faraway\n",
    "#only really an issue if in closest cluster though :) - because if it's closest, then it'll ruin the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255   0 178   0   0 118   0   0 166   0   0   0   0   0   0   0   0 228\n",
      " 183   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 199   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0 146   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 190   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 212   0   0   0   0   9   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   7   0   0\n",
      "  31   0   0   0   0 243   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 200   0   0   0   0 253   0   0 138   0   0   0   0   0   0  15 155\n",
      "  58  37   9   0   0   0 203   0  28   0   0 195   0   0   0   0   0   0\n",
      "   0   0   0   0   9   0  41   0   0   0  19  40   0 191   0 239   0   0\n",
      "   0   0   0   0 193   0   0 130   0   0   0   0   0  38   0   0   0  41\n",
      "   0   0   0  46   0   0 192  54   0   0   0   0 256  28   0 271 235   0\n",
      "   0   0   0   0   0 269  76   0   9   0   0   0   0   0   3   0   0  47\n",
      "   0 252   0  11 130   0   0  47   0   0  60   0  24   9   0   0   0 185\n",
      "   6   0 216   0   0   0  99   0   0   0   0   0 224   9   0   2   0   0\n",
      "   0   0 240   0   0   0 118   0   0   3   0   0 187 197   0   0  61   0\n",
      "   0 244   0   0 156   0 217   0   0   0   0 273   0   0   0 220 145  32\n",
      " 141   0 176   7   0   0  28  18   0   0 186   0  65   0   0   0 218   0\n",
      " 214   0 149   0 175   0  31   0  33   0   0 213   7   0  28   0   0   9\n",
      "  35   0   0   0 202   0  51 241   0   0   0   0   0   0   0 137   0   0\n",
      "   0   0  32   0   0  24 201 180 174 234 106   0   0   0   0   0 259   0\n",
      " 226 267  71   9   0   0   0   0   0  20  26   0  56   0   0  14 260   0\n",
      "   9   0  72   0   0   0   0   0  37 162 173   0   0  28  28  95   0   0\n",
      " 250   0   0   0  11   0 157 225   8   0   0   0   0   9   0   0 159 205\n",
      "   0   0   0   0 221   0  10 181 247   0   0   0   0  13   0  28   7   0\n",
      "   0 211   0  28   0   0  12   0   0   0  28 160 258   0   0 167  31  31\n",
      " 171   0   0   0   0 207   0 161 249   0   0 223   0  80   0 215   0 151\n",
      "   4   0  48   0 236  41   0 139   0   0 257 208   0   0  60  86 265   0\n",
      "   0   0   8   0 219   9   9   0   0   0 143   0  17   0   7  87   0   0\n",
      " 153   0 105  25   0   0  17   0  18 163   0 152  28   0   0   0   0  13\n",
      " 140   0   0  69 237  28  27   0  18  58   0  40  76 254  98   0 124 111\n",
      "  31   0   0  52 177 172   8   8  48   0   0 198   0   0   0   0  85  17\n",
      "   0   0  28   0   0   0  28  10 261   0   0  40   0 238   0   0  15 165\n",
      "   0  21   7 179   0 182 263  25   0   0  27   0  21 222   0 266  30  23\n",
      "   4 248   0 142 100   0  82   0  64   0   0  63 147  31  28   9   0   0\n",
      "   0 119  49 116   0  63   0   0  28   1  57 229 268  19  65  28   0   0\n",
      "  51 246  31   0   2  33   0  30 231 245 127   0  26 169   0   0 123   0\n",
      "   0   0   7 168   0  31 206   0   7 196   0   0  28   0  54   0   0   0\n",
      "  31   0 117   0   0   7  56   0   0  65   0 136   0   0 102 251   0 184\n",
      "   0 189  33   0 242   0   0 108 120   9  61   0   9 121 131  29 272   0\n",
      "  38   0 129   0   0 116   1 104 158   0   0  91 227   0   0   0 204   0\n",
      "   0 113  28   0   0  88 125  28   0   0   0   0   0   0  12  23 144   0\n",
      "  14   8  77   0 270 104  32   0  70   8   0   9   0   0   0   0   0   0\n",
      "  35   0  46  94   0 107 132 232   0   0   0 101   0   0  63  12  28  64\n",
      "   0 209 188   0   0 154 112  42   0  63   0 262  92   0   0  89 230  11\n",
      "   0   0   0  28 128   0   0 126   6   3   0   0  97   0 131 164   0 135\n",
      "   0   0  32   0   0 264  76   0   0   0  28  59   0  57 194  33  98   0\n",
      "   0   6 103 134  50   0   0  34   0   0  28   0 122   0   0   0   0   0\n",
      " 148  45  28   0   0   0   0 170   0   0  38   0 114   0  79 233   0  63\n",
      "  46 109   0  11   0  84  29  62   3  75   0  22   0   0  16   0  71  43\n",
      "  68  22   0   0   0  73   0  96  20 210   0   0 150   0  74  58   0  93\n",
      "  67   5  14   0   0   0   7   0   5  76   0  16   0   0  81  29  14   0\n",
      " 110 131 115   0   0   0   0  13  90  44   0  29   0  53   0  39 122 133\n",
      "  36  83   8   0   0  78   0  66  28  55]\n",
      "[['in', 'that', 'is', '##', 'The', 'said', 'was', 'the', 'at', 'not', 'as', 'it', 'be', 'are', 'I', 'have', 'he', 'will', 'has', '####', 'his', 'an', 'this', 'or', 'their', 'who', 'they', 'but', '$', 'had', 'year', 'were', 'we', 'more', '###', 'up', 'been', 'you', 'its', 'one', 'would', 'which', 'out', 'can', 'It', 'all', 'also', 'two', 'after', 'first', 'He', 'do', 'time', 'than', 'when', 'We', 'over', 'last', 'other', 'her', 'people', 'into', 'In', 'our', 'there', 'A', 'she', 'could', 'just', 'years', 'some', 'U.S.', 'three', 'million', 'them', 'what', 'But', 'so', 'no', 'like', 'if', 'only', 'percent', 'get', 'did', 'him', 'game', 'back', 'because', 'now', '#.#', 'before', 'company', 'any', 'team', 'off', 'This', 'most', 'made', 'through', 'make', 'second', 'state', 'well', 'day', 'season', 'says', 'week', 'where', 'down', 'being', 'government', 'your', 'home', 'going', 'my', 'good', 'They', \"'re\", 'should', 'many', 'way', 'those', 'four', 'during', 'such', 'may', 'very', 'how', 'since', 'take', 'including', 'then', '%', 'next', '#,###', 'much', 'still', 'go', 'think', 'old', 'even', '#.##', 'world', 'see', 'say', 'business', 'five', 'told', 'us', '1', 'these', 'If', 'And', 'me', 'play', 'help', '##,###', 'market', 'That', 'know', 'does', 'both', 'There', 'around', 'want', \"'ve\", 'For', 'got', 'third', 'school', 'left', 'another', 'country', 'need', '2', 'best', 'quarter', 'today', '##.#', 'same', 'Friday', 'month', 'billion', 'Tuesday', 'come', 'Monday', 'She', 'city', 'night', 'six', 'Thursday', '###,###', 'Wednesday', 'here', 'You', 'really', 'found', 'As', '3', 'lot', \"'m\", 'put', 'games', 'half', 'report', 'family', 'months', 'am', 'man', 'Saturday', 'too', 'better', 'days', 'came', 'American', 'show', 'past', 'took', 'added', 'expected', 'great', 'State', 'children', 'area', 'pm', 'big', 'few', 'per', 'Sunday', 'start', 'companies', 'little', 'ago', 'according', 'never', '5', 'sales', 'until', 'went', 'players', '##th'], [], [], ['called'], [], [], ['case'], ['work'], [], ['#-#', 'points', 'win', '##-##', 'point'], [], ['system'], [], [], [], ['end'], [], [], [], ['public'], [], [], [], [], ['early'], [], [], [], ['police', 'officials'], [], [], ['high'], [], [], [], [], [], ['information'], ['group'], [], ['run'], ['use', 'used'], [], [], [], [], ['money'], ['services', 'service'], [], [], [], [], [], [], ['program'], [], [], [], ['long'], [], ['members'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['life'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['without'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['on'], [], [], [], [], [], [], [], [], [], [], [], ['each', 'every'], [], [], [], [], [], [], [], ['between'], [], [], [], [], [], [], [], ['new'], [], [], [], [], [], [], [], [], ['AP'], [], [], [], [], [], [], [], [], [], [], ['with'], [], [], [], [], [], [], [], [], [], [], [], ['for'], [], [], [], [], ['by'], [], ['&'], [], [], [], [], ['against'], ['set'], ['support'], ['place'], [], ['based'], [], [], [], ['about'], ['under'], [], [], ['part'], [], [], [], [], [], [], [], [], ['while'], [], [], [], ['local'], [], [], [], [], [], [], [], [], [], [], [], ['from'], [], [], [], [], [], [], ['own'], [], [], [], ['top'], [], [], [], ['By'], [], [], [], [], [], [], [], [], ['hit'], ['right'], [], [], ['number'], [], [], [], [], [], [], [], [], [], [], [], [], ['lead'], [], ['former']]\n"
     ]
    }
   ],
   "source": [
    "#Agglomerative Clustering alg\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "x2 = AgglomerativeClustering(n_clusters = None, affinity='cosine', linkage = 'single', distance_threshold=0.5).fit(x)\n",
    "x2 = x2.labels_\n",
    "\n",
    "print(x2)\n",
    "\n",
    "clusters = [[] for x in range(300)]\n",
    "for i in range(1, 300):\n",
    "    clusters[x2[i]].append(z[i])\n",
    "while clusters[-1] == []:\n",
    "    clusters.pop()\n",
    "\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['##', '1', '2', '3', '5'], ['It', 'This', 'That'], ['two', 'three', 'four', 'five', 'six'], ['would', 'could', 'may'], ['But', 'And'], ['second', 'third'], ['#,###', '##,###', '###,###'], ['Friday', 'Tuesday', 'Monday', 'Thursday', 'Wednesday', 'Saturday', 'Sunday'], ['months', 'days'], ['in', 'for', 'that', 'is', 'on', 'The', 'with', 'said', 'was', 'the', 'at', 'not', 'as', 'it', 'be', 'from', 'by', 'are', 'I', 'have', 'he', 'will', 'has', '####', 'his', 'an', 'this', 'or', 'their', 'who', 'they', 'but', '$', 'had', 'year', 'were', 'we', 'more', '###', 'up', 'been', 'you', 'its', 'one', 'about', 'which', 'out', 'can', 'all', 'also', 'after', 'first', 'He', 'do', 'time', 'than', 'when', 'We', 'over', 'last', 'new', 'other', 'her', 'people', 'into', 'In', 'our', 'there', 'A', 'she', 'just', 'years', 'some', 'U.S.', 'million', 'them', 'what', 'so', 'no', 'like', 'if', 'only', 'percent', 'get', 'did', 'him', 'game', 'back', 'because', 'now', '#.#', 'before', 'company', 'any', 'team', 'against', 'off', 'most', 'made', 'through', 'make', 'state', 'well', 'day', 'season', 'says', 'week', 'where', 'while', 'down', 'being', 'government', 'your', '#-#', 'home', 'going', 'my', 'good', 'They', \"'re\", 'should', 'many', 'way', 'those', 'during', 'such', 'very', 'how', 'since', 'work', 'take', 'including', 'high', 'then', '%', 'next', 'By', 'much', 'still', 'go', 'think', 'old', 'even', '#.##', 'world', 'see', 'say', 'business', 'told', 'under', 'us', 'these', 'If', 'right', 'me', 'between', 'play', 'help', 'market', 'know', 'end', 'AP', 'long', 'information', 'points', 'does', 'both', 'There', 'part', 'around', 'police', 'want', \"'ve\", 'based', 'For', 'got', 'school', 'left', 'another', 'country', 'need', 'best', 'win', 'quarter', 'use', 'today', '##.#', 'same', 'public', 'run', 'set', 'month', 'top', 'billion', 'come', 'She', 'city', 'place', 'night', 'each', 'here', 'You', 'group', 'really', 'found', 'As', 'used', 'lot', \"'m\", 'money', 'put', 'games', 'support', 'program', 'half', 'report', 'family', 'number', 'officials', 'am', 'former', 'own', 'man', 'too', 'better', 'came', 'lead', 'life', 'American', '##-##', 'show', 'past', 'took', 'added', 'expected', 'called', 'great', 'State', 'services', 'children', 'hit', 'area', 'system', 'every', 'pm', 'big', 'service', 'few', 'per', 'members', 'early', 'point', 'start', 'companies', 'little', '&', 'case', 'ago', 'local', 'according', 'never', 'without', 'sales', 'until', 'went', 'players', '##th']]\n"
     ]
    }
   ],
   "source": [
    "#DBSCAN Clustering Alg\n",
    "from sklearn.cluster import DBSCAN\n",
    "x2 = DBSCAN(eps=0.2, min_samples=3, metric='cosine').fit(x)\n",
    "x2 = x2.labels_\n",
    "\n",
    "clusters = [[] for x in range(300)]\n",
    "for i in range(1, 300):\n",
    "    clusters[x2[i]].append(z[i])\n",
    "\n",
    "clusters = list(filter(None, clusters))\n",
    "\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key '' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m         z2 \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m curr_cluster\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m clusters \u001b[39m=\u001b[39m cluster300()\n",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 12\u001b[0m in \u001b[0;36mcluster300\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m z[i] \u001b[39min\u001b[39;00m touched_points:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m curr_cluster \u001b[39m=\u001b[39m make_cluster(z[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m clusters\u001b[39m.\u001b[39mappend(curr_cluster)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# print(\"check2\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(curr_cluster)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 12\u001b[0m in \u001b[0;36mmake_cluster\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m z2\u001b[39m.\u001b[39mremove(curr_word)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     closest_word \u001b[39m=\u001b[39m wv\u001b[39m.\u001b[39;49mmost_similar_to_given(curr_word, z2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mif\u001b[39;00m (closest_word \u001b[39min\u001b[39;00m z2):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         z2\u001b[39m.\u001b[39mremove(closest_word)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:654\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar_to_given\u001b[1;34m(self, key1, keys_list)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmost_similar_to_given\u001b[39m(\u001b[39mself\u001b[39m, key1, keys_list):\n\u001b[0;32m    653\u001b[0m     \u001b[39m\"\"\"Get the `key` from `keys_list` most similar to `key1`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m     \u001b[39mreturn\u001b[39;00m keys_list[argmax([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity(key1, key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys_list])]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:654\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmost_similar_to_given\u001b[39m(\u001b[39mself\u001b[39m, key1, keys_list):\n\u001b[0;32m    653\u001b[0m     \u001b[39m\"\"\"Get the `key` from `keys_list` most similar to `key1`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m     \u001b[39mreturn\u001b[39;00m keys_list[argmax([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity(key1, key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys_list])]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:1238\u001b[0m, in \u001b[0;36mKeyedVectors.similarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m   1222\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity\u001b[39m(\u001b[39mself\u001b[39m, w1, w2):\n\u001b[0;32m   1223\u001b[0m     \u001b[39m\"\"\"Compute cosine similarity between two keys.\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \n\u001b[0;32m   1225\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \n\u001b[0;32m   1237\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m     \u001b[39mreturn\u001b[39;00m dot(matutils\u001b[39m.\u001b[39munitvec(\u001b[39mself\u001b[39m[w1]), matutils\u001b[39m.\u001b[39munitvec(\u001b[39mself\u001b[39;49m[w2]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:404\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \n\u001b[0;32m    392\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    401\u001b[0m \n\u001b[0;32m    402\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[1;32m--> 404\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[0;32m    406\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:447\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    424\u001b[0m     \u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \n\u001b[0;32m    426\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    445\u001b[0m \n\u001b[0;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 447\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[0;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[0;32m    449\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:421\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[0;32m    420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 421\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key '' not present\""
     ]
    }
   ],
   "source": [
    "#bash list of clusters\n",
    "\n",
    "def cluster300():\n",
    "    #swap to snake_case\n",
    "    touched_points = []\n",
    "    clusters = []\n",
    "\n",
    "    for i in range (1000):\n",
    "        if z[i] in touched_points:\n",
    "            continue\n",
    "        curr_cluster = make_cluster(z[i])\n",
    "        clusters.append(curr_cluster)\n",
    "        # print(\"check2\")\n",
    "        # print(curr_cluster)\n",
    "        touched_points.extend(curr_cluster)\n",
    "        # print(touched_points)\n",
    "\n",
    "    #call other function to recursively add elements \n",
    "    #curr cluster = list\n",
    "    #append to total list of clusters\n",
    "    print(clusters)\n",
    "    return clusters\n",
    "\n",
    "#z = wv\n",
    "def make_cluster(word):\n",
    "    curr_cluster=[]\n",
    "    visited = []\n",
    "    queue = []\n",
    "    queue.append(word)\n",
    "    visited.append(word)\n",
    "\n",
    "    z2 = z.copy()\n",
    "\n",
    "    while len(curr_cluster) < 10 and queue:\n",
    "        curr_word = queue.pop(0)\n",
    "        if curr_word in curr_cluster:\n",
    "            break\n",
    "\n",
    "        curr_cluster.append(curr_word)\n",
    "\n",
    "        z2.remove(curr_word)\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            closest_word = wv.most_similar_to_given(curr_word, z2)\n",
    "            if (closest_word in z2):\n",
    "                z2.remove(closest_word)\n",
    "\n",
    "            if not (closest_word in visited):\n",
    "                queue.append(closest_word)\n",
    "                visited.append(closest_word)\n",
    "\n",
    "        z2 = z.copy()\n",
    "\n",
    "    return curr_cluster\n",
    "\n",
    "clusters = cluster300()\n",
    "\n",
    "#ALL THE METHODS ARE BASICALLY JUST BASH EVERYTHING, THEREFORE CREATE OWN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine distances for future clusters? Unfinished\n",
    "\n",
    "\n",
    "\n",
    "def check_clusters(clusters, data):\n",
    "    for i in range(len(clusters)):\n",
    "        for j in range(len(clusters[i])):\n",
    "            if (1-cosine(x.data, >): #need to fix lol\n",
    "                print\n",
    "        \n",
    "x = dataAnalysis(7, data)\n",
    "check_clusters(clusters, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'makeKeyVec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(dim):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         data[i]\u001b[39m.\u001b[39mprints()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m clusters_ndim(x, z)\n",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 14\u001b[0m in \u001b[0;36mclusters_ndim\u001b[1;34m(data, words)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(dim)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#basically what I want to do is sort the words for 'closeness' to the mean vector (origin) and then \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#first save words with data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m data \u001b[39m=\u001b[39m makeKeyVec(data, words)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#note that distance can be defined in any way sooo\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#far away things can still be the same distance from the rand\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m rand \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mdim\n",
      "\u001b[1;31mNameError\u001b[0m: name 'makeKeyVec' is not defined"
     ]
    }
   ],
   "source": [
    "#sorting algo\n",
    "\n",
    "#t-ttttttt sorting fails because two very far away points could still be the same distance from middle point :(\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def clusters_ndim (data, words):\n",
    "    dim = len(data[0])\n",
    "    print(dim)\n",
    "    #basically what I want to do is sort the words for 'closeness' to the mean vector (origin) and then \n",
    "    #first save words with data\n",
    "    data = makeKeyVec(data, words)\n",
    "    #note that distance can be defined in any way sooo\n",
    "\n",
    "    #far away things can still be the same distance from the rand\n",
    "    rand = [1]*dim\n",
    "    #need to find 'mean vector' - pca can't already do the mean vector stuff for me then :()\n",
    "    data.sort(key = lambda x: (1-cosine(x.data, rand)))\n",
    "    #need to add the words to the data, but ignore it in the vectors themselves\n",
    "    #check with the words directly above and directly below (maybe x 2? and same not in cluster method)\n",
    "    #then establish clusters\n",
    "    for i in range(dim):\n",
    "        data[i].prints()\n",
    "\n",
    "clusters_ndim(x, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive\\Java\\PCA\\PCAGit\\PCA-semantle\\SemantlePCA.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive/Java/PCA/PCAGit/PCA-semantle/SemantlePCA.ipynb#ch0000020?line=13'>14</a>\u001b[0m         keyvecs\u001b[39m.\u001b[39mappend(curr_keyvec)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive/Java/PCA/PCAGit/PCA-semantle/SemantlePCA.ipynb#ch0000020?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m keyvecs\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive/Java/PCA/PCAGit/PCA-semantle/SemantlePCA.ipynb#ch0000020?line=16'>17</a>\u001b[0m x2 \u001b[39m=\u001b[39m makeKeyVec(x, z)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "class KeyVec:\n",
    "    #figure out if cosine distance still works on pca\n",
    "    def __init__(self, data2, word2):\n",
    "        self.data = data2\n",
    "        self.word = word2\n",
    "\n",
    "    def prints(self):\n",
    "        print(str(self.word) + \": \" + str(self.data))\n",
    "\n",
    "def makeKeyVec(data, words):\n",
    "    keyvecs = []\n",
    "    for i in range(len(data)):\n",
    "        curr_keyvec = KeyVec(data[i], words)\n",
    "        keyvecs.append(curr_keyvec)\n",
    "    return keyvecs\n",
    "\n",
    "x2 = makeKeyVec(x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "300\n",
      "55\n",
      "300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1000, 0)) while a minimum of 1 is required by PCA.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 100>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(x[i]))\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m playable(\u001b[39m55\u001b[39;49m, x)\n",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 16\u001b[0m in \u001b[0;36mplayable\u001b[1;34m(dim, data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplayable\u001b[39m(dim, data):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     y \u001b[39m=\u001b[39m dataAnalysis(dim, data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     y2 \u001b[39m=\u001b[39m cluster_gen(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y2)):\n",
      "\u001b[1;32mc:\\Users\\Nishka\\OneDrive - Bellevue School District\\Coding\\PCA-semantle\\SemantlePCA.ipynb Cell 16\u001b[0m in \u001b[0;36mdataAnalysis\u001b[1;34m(dim, data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(data[\u001b[39m0\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components \u001b[39m=\u001b[39m newDim)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m pca\u001b[39m.\u001b[39;49mfit(arr2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m arr2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(pca\u001b[39m.\u001b[39mtransform(arr2))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Nishka/OneDrive%20-%20Bellevue%20School%20District/Coding/PCA-semantle/SemantlePCA.ipynb#X21sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m np\u001b[39m.\u001b[39mtranspose(maxTransform)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py:408\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m check_scalar(\n\u001b[0;32m    402\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_oversamples,\n\u001b[0;32m    403\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_oversamples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    404\u001b[0m     min_val\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    405\u001b[0m     target_type\u001b[39m=\u001b[39mnumbers\u001b[39m.\u001b[39mIntegral,\n\u001b[0;32m    406\u001b[0m )\n\u001b[1;32m--> 408\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    409\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py:456\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[1;32m--> 456\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    457\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    458\u001b[0m )\n\u001b[0;32m    460\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:918\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    916\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    917\u001b[0m     \u001b[39mif\u001b[39;00m n_features \u001b[39m<\u001b[39m ensure_min_features:\n\u001b[1;32m--> 918\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    919\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m feature(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m a minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    921\u001b[0m             \u001b[39m%\u001b[39m (n_features, array\u001b[39m.\u001b[39mshape, ensure_min_features, context)\n\u001b[0;32m    922\u001b[0m         )\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[0;32m    925\u001b[0m     array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(array, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1000, 0)) while a minimum of 1 is required by PCA."
     ]
    }
   ],
   "source": [
    "maxTransform = np.asarray([\n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],  \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "        [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],  \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "        [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [],  \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], \n",
    "    [], [], [], [], [], [], [], [], [], []\n",
    "])\n",
    "\n",
    "maxNum = 0\n",
    "\n",
    "def dataAnalysis(dim, data):\n",
    "\n",
    "    global maxTransform, maxNum\n",
    "    \n",
    "    if maxNum > dim:\n",
    "        maxTransform2 = np.transpose(maxTransform)\n",
    "        maxTransform2 = maxTransform2[:dim]\n",
    "        maxTransform2 = np.transpose(maxTransform2)\n",
    "        return maxTransform2\n",
    "\n",
    "    else:\n",
    "        newDim = dim - maxNum\n",
    "\n",
    "        arr2 = data[ : , 1000-newDim : data[0].__len__() ]\n",
    "        print(newDim)\n",
    "        print(len(data[0]))\n",
    "\n",
    "        pca = PCA(n_components = newDim)\n",
    "        pca.fit(arr2)\n",
    "        arr2 = np.asarray(pca.transform(arr2))\n",
    "\n",
    "        np.transpose(maxTransform)\n",
    "        np.transpose(arr2)\n",
    "        maxTransform = np.append(maxTransform, arr2, 1)\n",
    "        np.transpose(maxTransform)\n",
    "\n",
    "        # print(type(maxTransform))\n",
    "        # print(type(arr2))\n",
    "        # print(\"Max Transform # of vectors \" + str(maxTransform.__len__()))\n",
    "        # print(\"Max Transform Size of vectors \" + str(maxTransform[0].__len__()))\n",
    "\n",
    "        maxNum = dim\n",
    "        return maxTransform\n",
    "\n",
    "# x = np.array([[1, 2, 3, 4, 5], [2, 1, 3, 3, 1], [2, 4, 1, 2, 3], [4, 3, 2, 1, 4]])\n",
    "# print(dataAnalysis(2, x))\n",
    "# # print(dataAnalysis(3, x))\n",
    "\n",
    "#dataAnalysis(300, x)\n",
    "\n",
    "#perhaps describe how to do it with gradient function and the like to pick a random dimension\n",
    "#instead of going down one dimension at a time\n",
    "\n",
    "def playable(dim, data):\n",
    "\n",
    "    y = dataAnalysis(dim, data)\n",
    "    y2 = cluster_gen(y)\n",
    "\n",
    "    for i in range(len(y2)):\n",
    "        for j in range(len(y2[i])):\n",
    "            print(z[y2[i][j]], end = \" \")\n",
    "        if not (len(y2[i]) == 0):\n",
    "            print()\n",
    "\n",
    "    if dim >= 2: \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "print(len(x))\n",
    "print(len(x[i]))\n",
    "playable(55, x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(dim, data):\n",
    "    #data = np.array(data)\n",
    "    if dim == 3 or dim == 2:\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        plt.clf()\n",
    "\n",
    "        if dim == 3:\n",
    "            ax = fig.add_subplot(projection = \"3d\") #this is rectilinear, 3d, etc. projection= \"3d\"\n",
    "        elif dim == 2:\n",
    "            ax = fig.add_subplot(projection = \"rectilinear\")\n",
    "        \n",
    "        ax.set_position([0, 0, 0.95, 1])\n",
    "        plt.cla()\n",
    "           \n",
    "        if dim == 3:\n",
    "            ax.scatter(data[:, 0], data[:, 1], data[:, 2])\n",
    "            #not allowed to do it in 3 dimensions; b/c they expect a point of size two in annotation function\n",
    "            # for i in range (300):\n",
    "            #     ax.annotate(f.readline(), (data[i, 0], data[i, 1], data[i, 2]))\n",
    "            #     f.close()\n",
    "        elif dim == 2:\n",
    "            ax.scatter(data[:, 0], data[:, 1])\n",
    "            # plt.ylim(-1, 3)\n",
    "            # plt.xlim(-1.5, 2)\n",
    "            for i in range (300):\n",
    "                ax.annotate(z[i], (data[i, 0], data[i, 1]))\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"Too many/too few dimensions to visualize\")\n",
    "        ans = \"y\"\n",
    "        #ans = input(\"Proceed with 2-D? y/n\"\n",
    "        if ans == \"y\":\n",
    "            fig = plt.figure(figsize=(15 * dim, 15 * dim))\n",
    "            fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            for i in range(dim):\n",
    "                for j in range(i+1, dim):\n",
    "                    #dim, dim-1, (i+1)*(j+1\n",
    "                    ax = fig.add_subplot()\n",
    "                    ax.scatter(data[:, i], data[:, j])\n",
    "\n",
    "                    #with open(\"words.txt\", \"r\") as f:\n",
    "                        #ax.set_position([0, 0, 20.95, 20])\n",
    "                    for k in range (300):\n",
    "                        ax.annotate(z[i], (data[k, i], data[k, j]))\n",
    "                        #f.close()\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDim(data, start=1, end=300):\n",
    "    print(start)\n",
    "    print(end)\n",
    "    if start >= end:\n",
    "        return end\n",
    "    else:\n",
    "        mid = (start + end)//2\n",
    "        if not playable(mid, data):\n",
    "            return findDim(data, mid+1, end)\n",
    "        else:\n",
    "            return findDim(data, start, mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.array([[1, 2, 3, 4, 5], [2, 1, 3, 3, 1], [2, 4, 1, 2, 3], [4, 3, 2, 1, 4]])\n",
    "#OF COURSE IT WON'T WORK - IT'S A MAX OF 4 DIMENSIONS AND YOU'RE RUNNING 150 ON IT!\n",
    "print(len(x))\n",
    "#dataAnalysis(150, x)\n",
    "m = findDim(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b035a97ad67dff3ddcf42b4508c859b33be75c134f59f08fe6dd0d28f1650ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
